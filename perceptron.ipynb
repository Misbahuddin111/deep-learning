{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc56c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# --- 1. Generate synthetic admission data ---\n",
    "np.random.seed(42)\n",
    "n_samples = 20\n",
    "exam1 = np.random.randint(30, 100, n_samples)\n",
    "exam2 = np.random.randint(30, 100, n_samples)\n",
    "total = exam1 + exam2\n",
    "y = (total > 140).astype(int)\n",
    "# Add a little noise\n",
    "noise_idx = np.random.choice(n_samples, size=int(0.05*n_samples), replace=False)\n",
    "y[noise_idx] = 1 - y[noise_idx]\n",
    "\n",
    "data = pd.DataFrame({'Exam1': exam1, 'Exam2': exam2, 'Admitted': y})\n",
    "\n",
    "# --- 2. Split and scale ---\n",
    "X = data[['Exam1', 'Exam2']].values\n",
    "y = data['Admitted'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- 3. Train scikit-learn Perceptron ---\n",
    "perceptron = Perceptron(eta0=0.01, max_iter=20, random_state=42)\n",
    "perceptron.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- 4. Predict and evaluate ---\n",
    "y_pred = perceptron.predict(X_test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Weights:\", perceptron.coef_)\n",
    "print(\"Bias:\", perceptron.intercept_)\n",
    "\n",
    "# --- 5. Predict new applicants ---\n",
    "new_apps = np.array([[85, 80], [50, 45], [70, 68]])\n",
    "new_scaled = scaler.transform(new_apps)\n",
    "new_pred = perceptron.predict(new_scaled)\n",
    "for i, (e1, e2) in enumerate(new_apps):\n",
    "    status = \"Admitted\" if new_pred[i] == 1 else \"Not Admitted\"\n",
    "    print(f\"New Applicant {i+1}: Exam1={e1}, Exam2={e2} -> {status}\")\n",
    "\n",
    "# --- 6. Plot decision boundary (optional) ---\n",
    "w = perceptron.coef_[0]\n",
    "b = perceptron.intercept_[0]\n",
    "x_min, x_max = X_train[:, 0].min() - 10, X_train[:, 0].max() + 10\n",
    "y_min, y_max = X_train[:, 1].min() - 10, X_train[:, 1].max() + 10\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "mesh_scaled = scaler.transform(mesh_points)\n",
    "Z = perceptron.predict(mesh_scaled)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Paired)\n",
    "plt.scatter(X_train[y_train==1][:,0], X_train[y_train==1][:,1], \n",
    "            color='green', edgecolors='k', marker='o', label='Admitted (train)')\n",
    "plt.scatter(X_train[y_train==0][:,0], X_train[y_train==0][:,1], \n",
    "            color='red', edgecolors='k', marker='x', label='Not Admitted (train)')\n",
    "plt.scatter(X_test[y_test==1][:,0], X_test[y_test==1][:,1], \n",
    "            color='lime', edgecolors='k', marker='o', label='Admitted (test)')\n",
    "plt.scatter(X_test[y_test==0][:,0], X_test[y_test==0][:,1], \n",
    "            color='salmon', edgecolors='k', marker='x', label='Not Admitted (test)')\n",
    "plt.xlabel('Exam 1 Score')\n",
    "plt.ylabel('Exam 2 Score')\n",
    "plt.title('Perceptron Decision Boundary (Admission Prediction)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ee8ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2877177037.py, line 8)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef perceptronClass(X , y):\u001b[39m\n                               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "def perceptronClass(X , y,epoches = 10 , lr = 0.01):\n",
    "    n_samples , n_features = X.shape\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0\n",
    "    \n",
    "    for epochs in range(epoches):\n",
    "        for idx , x_i in enumerate(X):\n",
    "            linear = np.dot(x_i , weights) + bias\n",
    "            y_pred = 1 if linear > 0 else 0\n",
    "            # Perceptron trick: update if wrong\n",
    "            error = y[idx] - y_pred\n",
    "            if error != 0:\n",
    "                weights = weights + lr * error * x_i\n",
    "                bias = bias + lr *error\n",
    "            \n",
    "    return weights and bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
